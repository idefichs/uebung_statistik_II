[
  {
    "objectID": "Sitzung_4.html",
    "href": "Sitzung_4.html",
    "title": "Übung zu Statistik II - Sitzung 4",
    "section": "",
    "text": "In der heutigen Sitzung beschäftigen wir uns mit einem Datensatz, der in Anlehnung an (Lüke & Grosche, 2018) simuliert wurde. Dabei handelt es sich lediglich um eine Simulation zu Übungszwecken, die nicht die Originaldaten umfasst bzw. abbildet.\nIm Artikel wird untersucht, welche Einstellungen Studienteilnehmende gegenüber Inklusion haben und inwiefern diese durch verschiedene Einflussfaktoren bestimmt werden. Besonderes Augenmerk liegt auf dem Einfluss der wahrgenommenen Haltung der Organisation, die die Befragung durchführt. In zwei Experimenten wurde gezeigt, dass Einstellungen zur inklusiven Bildung nicht stabil sind, sondern stark vom sozialen Kontext beeinflusst werden."
  },
  {
    "objectID": "Sitzung_4.html#forschungsfragen",
    "href": "Sitzung_4.html#forschungsfragen",
    "title": "Übung zu Statistik II - Sitzung 4",
    "section": "1. Forschungsfragen",
    "text": "1. Forschungsfragen\nWir wollen in der heutigen Sitzung die folgenden drei Forschungsfragen analysieren:\n\nInwiefern verändert sich die Einstellung gegenüber Inklusion bezogen auf Bildungs-Outcomes (ati_edu) mit dem Alter?\nVerändert sich die Einstellung gegenüber Inklusion bezogen auf Bildungs-Outcomes (ati_edu) mit dem Alter und abhängig von der Einstellung gegenüber Inklusion bezogen auf soziale Outcomes (ati_soc)?\nVerändert sich die Einstellung gegenüber Inklusion bezogen auf Bildungs-Outcomes mit dem Alter in Abhängigkeit vom Geschlecht?"
  },
  {
    "objectID": "Sitzung_4.html#auswahl-geeigneter-statistischer-analyseverfahren",
    "href": "Sitzung_4.html#auswahl-geeigneter-statistischer-analyseverfahren",
    "title": "Übung zu Statistik II - Sitzung 4",
    "section": "2. Auswahl geeigneter statistischer Analyseverfahren",
    "text": "2. Auswahl geeigneter statistischer Analyseverfahren\n\nVorhersage einer metrische AV (ati_edu) durch eine metrische UV (age):\n➔ einfache lineare Regression\nVorhersage einer metrische AV (ati_edu) durch mehr als eine metrische UV (hier: age, ati_soc):\n➔ multiple lineare Regression\nVorhersage einer metrische AV (ati_edu) durch mind. eine metrische UV (hier: age) und mind. eine binär kodierte UV (hier: sex):\n➔ multiple lineare Regression mit Dummycodierung"
  },
  {
    "objectID": "Sitzung_4.html#vorbereitung-und-durchführung-der-statistischen-verfahren",
    "href": "Sitzung_4.html#vorbereitung-und-durchführung-der-statistischen-verfahren",
    "title": "Übung zu Statistik II - Sitzung 4",
    "section": "3. Vorbereitung und Durchführung der statistischen Verfahren",
    "text": "3. Vorbereitung und Durchführung der statistischen Verfahren\n\n3.1 Datensatz laden\n\nVariante 1\nDen Datensatz über die Angabe des vollständigen Dateipfades einlesen.\n\n# Daten einlesen\ndf &lt;- read.csv2(\"Hier/kompletten/Pfad/zur/Datei/data_inklusion.csv\")\n\n\n\nVariante 2\nEin geeignetes Arbeitsverzeichnis setzen und dort den Datensatz abspeichern. Dann benötigt der Einlese-Befehl nur noch den Dateinamen.\n\n# Arbeitsverzeichnis setzen\nsetwd(\"Hier/kompletten/Pfad/zur/Datei\")\n# optional: Überprüfung des aktuellen Arbeitsverzeichnisses\ngetwd()\n# Daten einlesen\ndf &lt;- read.csv2(\"data_inklusion.csv\")\n\n\n\n\n3.2 Überblick über den Datensatz\nEinen guten Überblick über Inhalt, Struktur und erste deskriptive Statistiken des Datensatzes erhält man z. B. mit den beiden Befehlen str() und summary().\n\nstr(df)\n\n'data.frame':   231 obs. of  11 variables:\n $ group    : chr  \"Group A\" \"Group A\" \"Group A\" \"Group A\" ...\n $ sex      : int  0 1 1 0 1 1 1 0 0 1 ...\n $ children : int  0 0 0 0 0 1 0 0 0 0 ...\n $ age      : int  27 39 21 42 36 27 30 48 27 39 ...\n $ contact  : int  1 1 1 1 1 1 1 0 0 1 ...\n $ edu_prof : int  0 0 0 1 1 0 1 1 0 1 ...\n $ education: int  6 8 7 5 9 6 8 8 6 11 ...\n $ politics : int  5 5 3 2 2 3 6 3 6 6 ...\n $ att_org  : int  7 5 6 6 4 2 6 4 4 6 ...\n $ ati_edu  : num  22.9 18.8 26.4 19 24.7 ...\n $ ati_soc  : num  9.32 11.46 18.14 8.71 11.77 ...\n\nsummary(df)\n\n    group                sex           children           age       \n Length:231         Min.   :0.000   Min.   :0.0000   Min.   :17.00  \n Class :character   1st Qu.:0.000   1st Qu.:0.0000   1st Qu.:27.00  \n Mode  :character   Median :0.000   Median :0.0000   Median :35.00  \n                    Mean   :0.303   Mean   :0.1169   Mean   :34.34  \n                    3rd Qu.:1.000   3rd Qu.:0.0000   3rd Qu.:40.00  \n                    Max.   :1.000   Max.   :1.0000   Max.   :62.00  \n    contact          edu_prof        education         politics    \n Min.   :0.0000   Min.   :0.0000   Min.   : 2.000   Min.   :0.000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.: 6.000   1st Qu.:3.000  \n Median :1.0000   Median :0.0000   Median : 7.000   Median :4.000  \n Mean   :0.7273   Mean   :0.3766   Mean   : 7.143   Mean   :3.892  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.: 8.000   3rd Qu.:5.000  \n Max.   :1.0000   Max.   :1.0000   Max.   :12.000   Max.   :8.000  \n    att_org         ati_edu         ati_soc      \n Min.   :1.000   Min.   :13.24   Min.   : 1.000  \n 1st Qu.:3.000   1st Qu.:19.39   1st Qu.: 9.563  \n Median :5.000   Median :21.96   Median :11.865  \n Mean   :4.312   Mean   :21.91   Mean   :11.768  \n 3rd Qu.:6.000   3rd Qu.:24.25   3rd Qu.:13.862  \n Max.   :7.000   Max.   :31.74   Max.   :21.290  \n\n\n\n# weitere nützliche Befehle\nhead(df)\ntail(df)\nnrow(df)\nncol(df)\nlibrary(psych)\ndescribe(df) # deskriptive Statistiken: describe() aus dem package psych enthält mehr/andere Informationen als summary().\ndescribeBy(df, df$group) # deskriptive Statistiken: describeBy() aus dem package psych gibt Statistiken gesplittet nach Gruppen aus.\n\nWir wissen nun, welche Variablen im Datensatz enthalten sind, aber kennen die Kodierungen nicht. Deshalb benötigen wir noch mehr Informationen aus dem Artikel. Diese finden sich z. B. auf S. 44. Damit können wir eine Art codebook erstellen:\n\ncodebook\n\n\n\n\n\n\n\n\nVariable\nBeschreibung\nKodierung\n\n\n\n\ngroup\ndurchführende Organisation\nA, B, C, D (siehe Artikel)\n\n\nsex\nGeschlecht\n0 = weiblich, 1 = männlich\n\n\nchildren\nKind(er)?\n0 = nein, 1 = ja\n\n\nage\nAlter\nmetrisch: Alter in Jahren\n\n\ncontact\nKontakt zu Personen mit Behinderung?\n0 = nein, 1 = ja\n\n\nedu_prof\nBeruf im Bildungsbereich?\n0 = nein, 1 = ja\n\n\neducation\nBildungsniveau\nmetrisch: Anzahl der Schuljahre\n\n\npolitics\nPolitische Einstellung\n1 = links, 10 = rechts\n\n\natt_org\nWahrgenommene Einstellung der durchführenden Organiation\n1 = absolut gegen Inklusion bis 7 = absolut für Inklusion\n\n\nati_edu\nEinstellung gegenüber Inklusion (Bildungsoutcomes)\n0, …, 35: Summe über 7 Items von 0 = Stimme nicht zu. bis 5 = Stimme zu.\n\n\nati_soc\nEinstellung gegenüber Inklusion (soziale Outcomes)\n0, …, 25: Summe über 5 Items von 0 = Stimme nicht zu. bis 5 = Stimme zu.\n\n\n\n\n\n\n3.3 Voraussetzungen prüfen\n\nLinearer Zusammenhang zwischen AV und allen (nicht binär kodierten) UV(s)\nNormalverteilung der Residuen\nHomoskedastizität der Residuen\nbei multiplen Regressionen: UVs auf Multikollinearität überprüfen\n\nDie Voraussetzungen 1 & 4 können überprüft werden, bevor die Modelle geschätzt werden. Für 2 & 3 benötigen wir die Residuen, die wir aber erst im Zuge der Schätzung der Modelle erhalten.\n\n3.3.1 Überprüfung der Linearität\nDie Linearität kann visuell, z. B. mit Hilfe eines Streudiagramms (scatterplot) überprüft werden. Eine feststehendes Kriterium, ab wann ein Zusammenhang als linear gewertet wird, gibt es allerdings nicht.\nForschungsfrage 1:\n\n\nbase R\n\n# zur Erinnerung: ~ = \"in Abhängigkeit von\"\n# für Plots bedeutet das: y-Achse ~ x-Achse\nplot(ati_edu ~ age, data = df,\n     main = \"ATI nach Alter\",\n     xlab = \"Alter\",\n     ylab = \"ATI (Bildungs-Outcomes)\",\n     ylim = c(min(df$ati_edu)-2,32),\n     pch = 19,         # volle Punkte\n     col = \"#D22E4C\") # Farbe der Punkte\n\n\n\n\n\n\n\n\n\n\n\nggplot\n\nlibrary(ggplot2)\nggplot(data = df, aes(x = age, y = ati_edu)) +\n  geom_point(color =  \"#D22E4C\") +\n  labs(\n    title = \"ATI nach Alter\",\n    x = \"Alter\",\n    y = \"ATI (Bildungs-Outcomes)\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nForschungsfrage 2:\n\n\nbase R\n\n# zur Erinnerung: ~ = \"in Abhängigkeit von\"\n# für Plots bedeutet das: y-Achse ~ x-Achse\nplot(ati_edu ~ ati_soc, data = df,\n     main = \"ATI_EDU in Abhängigkeit von ATI_SOC\",\n     xlab = \"ATI (soziale Outcomes)\",\n     ylab = \"ATI (Bildungs-Outcomes)\",\n     ylim = c(min(df$ati_edu)-2,32),\n     pch = 19,         # volle Punkte\n     col = \"#D22E4C\") # Farbe der Punkte\n\n\n\n\n\n\n\n\n\n\n\nggplot\n\nlibrary(ggplot2)\nggplot(data = df, aes(x = ati_soc, y = ati_edu)) +\n  geom_point(color =  \"#D22E4C\") +\n  labs(\n    title = \"ATI_EDU in Abhängigkeit von ATI_SOC\",\n    x = \"ATI (soziale Outcomes)\",\n    y = \"ATI (Bildungs-Outcomes)\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nFazit:\nFür beide Forschungsfragen nehmen wir nach Inspektion der Streudiagramme lineare Zusammenhänge an.\n\n\n3.3.2 Überprüfung auf Multikollinearität\nMultikollinearität muss nur für Forschungsfrage 2 überprüft werden, weil hier mindestens zwei metrische Prädiktoren (UVs) ins Modell eingehen. Die multiple Regressionsanalyse liefert nur dann verlässliche Ergebnisse, wenn die Prädiktoren nicht zu hoch miteinander korrelieren. Ein Beispiel für hohe Kollinearität wäre etwa die größe einer Wohnung und die Anzahl der Zimmer. In diesem Fall kann man eine UV bereits durch eine (oder auch mehrere) weitere UV(s) vorhersagen, was zu Problemen in der Schätzgenauigkeit und Interpretierbarkeit des Modells führen kann.\nMultikollinearität kann auf zwei Arten überprüft werden:\nvisuell durch z. B. ein Streudiagramm der beiden Prädiktoren\n\n\nbase R\n\n# zur Erinnerung: ~ = \"in Abhängigkeit von\"\n# Für die Überprüfung der Kollinearität ist die Reihenfolge der UVs egal\nplot(age ~ ati_soc, data = df,\n     main = \"Alter in Abhängigkeit von ATI_SOC\",\n     xlab = \"ATI (soziale Outcomes)\",\n     ylab = \"Alter\",\n     ylim = c(min(df$age)-2, max(df$age)+2),\n     pch = 19,         # volle Punkte\n     col = \"#D22E4C\") # Farbe der Punkte\n\n\n\n\n\n\n\n\n\n\n\nggplot\n\nlibrary(ggplot2)\nggplot(data = df, aes(x = ati_soc, y = age)) +\n  geom_point(color =  \"#D22E4C\") +\n  labs(\n    title = \"Alter in Abhängigkeit von ATI_SOC\",\n    x = \"ATI (soziale Outcomes)\",\n    y = \"Alter\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nstatistisch durch die Berechnung der Korrelation:\n\ncor(df$age, df$ati_soc)\n\n[1] -0.6059036\n\n\nAb einer Pearson-Korrelation von ca. .70 sollte man noch einmal genau prüfen, ob Kollinearität vorliegt (z. B. auch mittels VIF [Variance Inflation Factor]) und ob beide Variablen im Regressionsmodell benötigt werden. Auch hier gilt: Faustregel, kein absoluter Schwellenwert!\nBei mehr als zwei metrischen UVs ist eine Korrelationsmatrix sinnvoll. Da Multikollinearität aber auch dann vorliegen kann, wenn sich ein Prädiktor durch eine (lineare) Kombination anderer Prädiktoren vorhersagen lässt, reicht eine Korrelationsmatrix nicht immer aus. In diesem Fall ist die Verwendung des VIF empfohlen.\nFazit:\nIn unserem Fall korrelieren die beiden Prädiktoren zwar durchaus hoch, aber noch in einem “vertretbaren Rahmen”, d. h. sie könnten im Modell möglicherweise beide substanziell zur Erklärung von Varianz in der AV beitragen.\n\n\n\n3.4. Aufstellen der Modelle\n\n\n\n# zu Forschungsfrage 1\nmod1 &lt;- lm(df$ati_edu ~ df$age)\n\n\n\n# 2D-Plot mit base R\nplot(df$ati_edu ~ df$age,\n     xlab = \"Alter\",\n     ylab = \"ATI (Bildungs-Outcomes\",\n     col = \"#D22E4C\",\n     pch = 16)\n\n# Regressionsgerade einzeichnen\nabline(mod1, col = \"#F2CCD4\", lwd = 4)\n\n\n\n\n\n\n\n\n\n\n\n\n# zu Forschungsfrage 2\nmod2 &lt;- lm(ati_edu ~ age + ati_soc, data = df)\n# Je mehr Prädiktoren, desto schwieriger wird die Visualisierung des Modells.\n# Mehr als drei Dimensionen (2 Prädiktoren + 1 Kriterium) kann man sich nicht mehr vorstellen.\n\n# 3D Plot\nlibrary(scatterplot3d)\ns3d &lt;- scatterplot3d(df$age, df$ati_soc, df$ati_edu, pch = 16, color = \"#D22E4C\",\n                     xlab = \"Alter\", ylab = \"ATI (soziale Outcomes)\", zlab = \"ATI (Bildungs-Outcomes\")\n\n# Regressionsebene einzeichnen\ns3d$plane3d(mod2)\n\n\n\n\n\n\n\n\n\n\n\n\n# zu Forschungsfrage 3\nmod3 &lt;- lm(ati_edu ~ age + sex, data = df)\n\n\n\n\n\n3.5. Prüfung der restlichen Voraussetzungen\nNachdem die Modelle geschätzt sind, können nun auch die restlichen Voraussetzungen überprüft werden, d. h. insbesondere die Normalverteilung der Residuen und die Homoskedastizität der Residuen.\nHat man die Modelle geschätzt, kann man in R leicht auf die Residuen bzw. geschätzten (auch: vorhergesagten, gefitteten) Werte zugreifen:\n\nresid(model) bzw residuals(model) liefert die Residuen des jeweiligen Modells.\nfitted(model) liefert die vorhergesagten Werte, also diejenigen, die auf der Regressionsgerade liegen.\n\nZum Beispiel für unser Modell 1:\n\nresid(mod1)[1:12] # Die Residuen für die ersten 12 Fälle im Datensatz\n\n         1          2          3          4          5          6          7 \n-0.4976589 -2.1268388  1.8027553 -1.3604928  3.1015034  2.9218840  2.2190329 \n         8          9         10         11         12 \n 2.6466850 -0.2014620  0.5806697 -1.5432726 -2.9652863 \n\nfitted(mod1)[1:12] # Die geschätzten Werte der AV (hier: ati_edu) für die ersten 12 Fälle im Datensatz\n\n       1        2        3        4        5        6        7        8 \n23.40243 20.96350 24.62189 20.35377 21.57323 23.40243 22.79269 19.13431 \n       9       10       11       12 \n23.40243 20.96350 24.82513 25.02837 \n\n\n\n3.5.1 Normalverteilung der Residuen\nDamit wir nicht immer wieder die Funktion resid()schreiben müssen, speichern wir die Residuen zunächst jeweils in einem neuen Objekt:\n\nresid1 &lt;- resid(mod1)\nresid2 &lt;- resid(mod2)\nresid3 &lt;- resid(mod3)\n\nOb die Residuen normalverteilt sind, kann wieder auf zwei Arten überprüft werden: visuell oder mit Hilfe eines statistischen Tests.\nvisuell\n Quelle: Artwork by allison_horst\nGeeignete Visualisierungen sind u. a. Histogramme oder Q-Q-Plots.\nForschungsfrage 1:\n\n\nbase R\n\nhist(resid1, col = \"#D22E4C\", breaks = 24,\n     xlim = c(-10, 10),\n     ylim = c(0,25),\n     main = \"Histogramm der Residuen von Modell 1\",\n     xlab = \"Residuen\",\n     ylab = \"Häufigkeit\")\n\n\n\n\n\n\n\nqqnorm(resid1, col = \"#D22E4C\",\n       main = \"Q-Q-Plot der Residuen von Modell 1\",\n       xlab = \"Theoretische Quantile\",\n       ylab = \"Empirische Quantile\",\n       pch = 16)\nqqline(resid1)\n\n\n\n\n\n\n\n\n\n\n\nggplot\n\nggplot(data.frame(resid1), aes(x = resid1)) +\n  geom_histogram(color = \"black\", fill = \"#D22E4C\", bins = 20) +\n  labs(title = \"Histogramm der Residuen von Modell 1\",\n       x = \"Residuen\",\n       y = \"Häufigkeit\") +\n  theme_minimal()\n\n\n\n\n\n\n\nggplot(data.frame(resid1), aes(sample = resid1)) +\n  stat_qq(color = \"#D22E4C\") +\n  stat_qq_line() +\n  labs(title = \"Q-Q-Plot der Residuen von Modell 1\",\n       x = \"Theoretische Quantile\", y = \"Empirische Quantile\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nMit analogem Code können nun die entsprechenden Plots für unsere Modelle 2 und 3 erzeugt werden.\nForschungsfrage 2:\n\n\nbase R\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nForschungsfrage 3:\n\n\nbase R\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFazit:\nFür alle drei Modelle sind die Residuen annähernd normalverteilt. Bei Histogrammen ist immer zu beachten, dass die Argumente bins bzw. breaks das Aussehen der Verteilung beeinflussen. Daher sehen die Plots auch unterschiedlich aus, je nachdem ob base R oder ggplot verwendet wird. (Mit etwas mehr Code ist es aber auch möglich, gleiche Plots zu erzeugen.) Sind die Argumente ungünstig gewählt, lässt sich eine Normalverteilung u. U. nicht erkennen. Zum Beispiel ergibt sich für unser Modell 1 und unterschiedliche Werte für das Argument bins:\n\n\n\n# bins = 10\n\nggplot(data.frame(resid1), aes(x = resid1)) +\n  geom_histogram(color = \"black\", fill = \"#D22E4C\", bins = 10) +\n  labs(title = \"Histogramm der Residuen von Modell 1\",\n       x = \"Residuen\",\n       y = \"Häufigkeit\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n# bins = 30\n\nggplot(data.frame(resid1), aes(x = resid1)) +\n  geom_histogram(color = \"black\", fill = \"#D22E4C\", bins = 30) +\n  labs(title = \"Histogramm der Residuen von Modell 1\",\n       x = \"Residuen\",\n       y = \"Häufigkeit\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nQ-Q-Plots sind dahingehend eine etwas verlässlichere Visualisierungsmöglichkeit. Die Punkte sollten hierbei möglichst auf der eingezeichneten Geraden liegen. An den beiden “Enden” der Geraden gibt es fast immer Abweichungen, weil in diesen Bereichen nur wenige Datenpunkte vorliegen, was die Quantilschätzungen unsicherer macht, sie besonders empfindlich gegenüber Ausreißern sind und sich Unterschiede zwischen der beobachteten und der theoretischen Verteilung vor allem in den Randbereichen deutlich bemerkbar machen.\n\nstatistisch: Geeignete statistische Tests sind u. a. der Shapiro-Wilk-Test oder der Kolmogorov-Smirnov-Test. Exemplarisch für unser Modell 1:\n\n\nShapiro-Wilk-Test\n\nshapiro.test(resid1)\n\n\n    Shapiro-Wilk normality test\n\ndata:  resid1\nW = 0.99269, p-value = 0.3117\n\n\n\n\n\nKolmogorov-Smirnov-Test\n\nks.test(resid1, \"pnorm\", mean=mean(resid1), sd=sd(resid1))\n\n\n    Asymptotic one-sample Kolmogorov-Smirnov test\n\ndata:  resid1\nD = 0.041448, p-value = 0.8223\nalternative hypothesis: two-sided\n\n\n\n\n\nWährend der Shapiro-Wilk-Test immer auf Normalverteilung testet, testet der Kolmogorov-Smirnov-Test grundsätzlich auf Verteilungen und benötigt nähere Angaben, auf welche Verteilung nun genau getestet werden soll. In unserem Fall ist das die Normalverteilung, die durch den Mittelwert und die Standardabweichung festgelegt ist. Deshalb werden diese beiden Parameter ebenfalls als Argumente übergeben.\nBeide Tests haben die Nullhypothese “Normalverteilung liegt vor”. Wird der Test signifikant, würde man also die Nullhypothese ablehnen. Wäre das der Fall, wäre die Voraussetzung der normalverteilten Residuen verletzt.\nFazit:\nIn unserem Fall werden beide Tests nicht signifikant, wir gehen also von Normalverteilung aus. Grundsätzlich empfiehlt sich immer auch die visuelle Überprüfung, da beide Tests (unterschiedliche) Schwachstellen besitzen und in bestimmten Fällen (z. B. Ausreißer) die Normalverteilung zu schnell “ablehnen” und in anderen Fällen (z. B. zu geringe Power bei kleinen Stichproben) eine Abweichung der Normalverteilung möglicherweise nicht erkennen.\n\n\n3.5.2 Homoskedaszität der Residuen überprüfen\nHomoskedastizität kann ebenfalls gut visuell überprüft werden. Ein geeignetes Mittel ist der sog. Residual-vs-Fitted-Plot.\nBei Homoskedastizität sollte kein Muster erkennbar sein, d. h. die Punkte sollten zufällig um die Nulllinie streuen, ohne z. B. einem Trichter zu ähneln.\nForschungsfrage 1:\n\n\nbase R\n\nplot(fitted(mod1), resid1,\n     col = \"#D22E4C\",\n     pch = 16,\n     main = \"Residuals vs Fitted – Modell 1\",\n     xlab = \"Vorhergesagte Werte\",\n     ylab = \"Residuen\")\nabline(h = 0, col = \"black\", lwd = 3)\n\n\n\n\n\n\n\n\n\n\n\nggplot\n\nggplot(data.frame(fitted = fitted(mod1), resid = resid1),\n       aes(x = fitted, y = resid)) +\n  geom_point(color = \"#D22E4C\") +\n  geom_hline(yintercept = 0, linetype = \"solid\") +\n  labs(title = \"Residuals vs Fitted – Modell 1\",\n       x = \"Vorhergesagte Werte\",\n       y = \"Residuen\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nMit analogem Code können nun die entsprechenden Plots für unsere Modelle 2 und 3 erzeugt werden.\nForschungsfrage 2:\n\n\nbase R\n\n\n\n\n\n\n\n\n\n\n\n\nggplot\n\n\n\n\n\n\n\n\n\n\n\nForschungsfrage 3:\n\n\nbase R\n\n\n\n\n\n\n\n\n\n\n\n\nggplot\n\n\n\n\n\n\n\n\n\n\n\nFazit:\nDie graphische Überprüfung deutet auf Homoskedastizität hin. Es sind keine auffälligen Muster zu erkennen.\nDa wir nun also alle notwendigen Voraussetzungen überprüft haben und diese jeweils für alle drei Modelle erfüllt sind, können wir diese nun auch sinnvollerweise interpretieren."
  },
  {
    "objectID": "Sitzung_4.html#interpretation",
    "href": "Sitzung_4.html#interpretation",
    "title": "Übung zu Statistik II - Sitzung 4",
    "section": "4. Interpretation",
    "text": "4. Interpretation\nUm die zur Interpretation nötigen Informationen (Parameterschätzungen, p-Werte, …) zu erhalten, nutzen wir die Funktion summary().\n\n4.1 Forschungsfrage 1\nFrage:\nInwiefern verändert sich die Einstellung gegenüber Inklusion bezogen auf Bildungs-Outcomes (ati_edu) mit dem Alter?\n\nsummary(mod1)\n\n\nCall:\nlm(formula = df$ati_edu ~ df$age)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8.0271 -2.1263 -0.0693  2.3967  7.9186 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 28.89000    0.71953   40.15   &lt;2e-16 ***\ndf$age      -0.20324    0.02012  -10.10   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.053 on 229 degrees of freedom\nMultiple R-squared:  0.3082,    Adjusted R-squared:  0.3052 \nF-statistic:   102 on 1 and 229 DF,  p-value: &lt; 2.2e-16\n\n\n\n geschätzte Regressionsgleichung:\nati_edu = 28.89 − 0.203 ⋅ age\nDas hieße z. B. eine durchschnittliche Person im Alter von 50 Jahren hätte einen geschätzten ati_edu-Wert von\n28.89 - 0.203 ⋅ 50 = 18.74\nInterpretation:\n\nIntercept (28.89):\nWenn das Alter 0 wäre (was inhaltlich hier keinen realistischen Sinn ergibt), wäre die vorhergesagte Einstellung gegenüber Inklusion 28.89 Punkte. In diesem Kontext ist der Achsenabschnitt also rein technisch/hypothetisch zu interpretieren.\nAlter (−0.20324):\nMit jedem weiteren Lebensjahr sinkt die Einstellung gegenüber Inklusion im Durchschnitt um 0.20 Punkte. Der negative Koeffizient weist darauf hin, dass ältere Personen tendenziell eine negativere Einstellung gegenüber Inklusion haben. Der Effekt ist signifikant.\nModellgüte\n\nVarianzaufklärung (R² = 0.3082 / Adjusted R² = 0.3052):\nDas Modell erklärt ca. 30.8% der Varianz in der Einstellung gegenüber Inklusion. Für sozialwissenschaftliche Modelle ist das ein mittlerer Effekt.\nF-Test p-Wert &lt; 2.2e-16:\nDas Gesamtmodell ist signifikant. Die Prädiktorvariable “Alter” trägt also statistisch signifikant zur Vorhersage bei.\n\n\n\n\n4.2 Forschugnsfrage 2\nFrage:\nVerändert sich die Einstellung gegenüber Inklusion bezogen auf Bildungs-Outcomes (ati_edu) mit dem Alter und abhängig von der Einstellung gegenüber Inklusion bezogen auf soziale Outcomes (ati_soc)?\n\nsummary(mod2)\n\n\nCall:\nlm(formula = ati_edu ~ age + ati_soc, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8.1687 -2.0942 -0.1002  2.4357  7.8579 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 28.37385    1.56742  18.102  &lt; 2e-16 ***\nage         -0.19755    0.02534  -7.796 2.27e-13 ***\nati_soc      0.02725    0.07347   0.371    0.711    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.059 on 228 degrees of freedom\nMultiple R-squared:  0.3086,    Adjusted R-squared:  0.3026 \nF-statistic: 50.89 on 2 and 228 DF,  p-value: &lt; 2.2e-16\n\n\n\n geschätzte Regressionsgleichung:\nati_edu = 28.37 − 0.198 ⋅ age + 0.027 ⋅ ati_soc\nDas hieße z. B. eine durchschnittliche Person im Alter von 50 Jahren und einem ati_soc-Wert von 20 hätte einen geschätzten ati_edu-Wert von\n28.37 − 0.198 ⋅ 50 + 0.027 ⋅ 20 = 18.73\nInterpretation:\n\nIntercept (28.37):\nWenn sowohl das Alter als auch ati_soc den Wert 0 hätten (was unrealistisch ist), läge die vorhergesagte Einstellung gegenüber Inklusion bei 28.37 Punkten. In diesem Kontext ist der Achsenabschnitt also rein technisch/hypothetisch zu interpretieren.\nAlter (−0.19755):\nMit jedem weiteren Lebensjahr sinkt die Einstellung gegenüber Inklusion im Durchschnitt um rund 0.20 Punkte. Der negative Koeffizient weist darauf hin, dass ältere Personen tendenziell eine negativere Einstellung gegenüber Inklusion haben. Der Effekt ist signifikant.\nSoziale Einstellung gegenüber Inklusion (ati_soc = 0.02725):\nDer geschätzte Effekt ist positiv, aber nicht signifikant (p = 0.711). Die Variable trägt also nicht signifikant zur Vorhersage bei.\nModellgüte\n\nVarianzaufklärung (R² = 0.3086 / Adjusted R² = 0.3026):\nDie Varianzaufklärung liegt weiterhin bei ca. 30.9%, vergleichbar mit Modell 1. Die zusätzliche Prädiktorvariable (ati_soc) verbessert das Modell also kaum.\nF-Test p-Wert &lt; 2.2e-16:\nDas Gesamtmodell ist signifikant – mindestens ein Prädiktor (hier: Alter) trägt signifikant zur Vorhersage bei.\n\n\n\n\n4.3 Forschugnsfrage 3\nFrage:\nVerändert sich die Einstellung gegenüber Inklusion bezogen auf Bildungs-Outcomes mit dem Alter in Abhängigkeit vom Geschlecht?\n\nsummary(mod3)\n\n\nCall:\nlm(formula = ati_edu ~ age + sex, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8.1139 -1.9601 -0.1178  2.4351  8.1400 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 28.96572    0.72790  39.793   &lt;2e-16 ***\nage         -0.20266    0.02016 -10.053   &lt;2e-16 ***\nsex         -0.31568    0.43788  -0.721    0.472    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.056 on 228 degrees of freedom\nMultiple R-squared:  0.3098,    Adjusted R-squared:  0.3037 \nF-statistic: 51.17 on 2 and 228 DF,  p-value: &lt; 2.2e-16\n\n\n\n geschätzte Regressionsgleichung:\nati_edu = 28.97 − 0.203 ⋅ age − 0.316 ⋅ sex\nDa es sich hierbei um eine Dummy-Regression handelt, ergibt sich folglich für\n- weibliche Personen (sex = 0): ati_edu = 28.97 − 0.203 ⋅ age - männliche Personen (sex = 1): ati_edu = 28.97 − 0.203 ⋅ age − 0.316 ⋅ 1 = 28.654 − 0.203 ⋅ age\nWir sehen also, dass sich der Intercept zwischen den beiden Gruppen verändert, nicht aber die Steigung.\n(Weiterführend: Möchte man nun noch ein mögliches Wechselspiel zwiscehn Alter und Geschlecht mit modellieren, also dass z. B. sich das Geschlecht in unterschiedlichen Altersgruppen unterschiedlich auswirkt, müsste man noch einen Interaktionsterm mitaufnehmen. Dadurch kann auch die Steigung zwischen beiden Gruppen variieren.)\nDas hieße z. B. eine durchschnittliche\n- weibliche Person im Alter von 50 Jahren hätte einen geschätzten ati_edu-Wert von\n28.97 − 0.203 ⋅ 50 = 18.82 - männliche Person im Alter von 50 Jahren hätte einen geschätzten ati_edu-Wert von 28.654 − 0.203 ⋅ 50 = 18.504\nInterpretation:\n\nIntercept (28.97):\nDie vorhergesagte Einstellung gegenüber Inklusion liegt bei 28.97 Punkten für eine Person mit Alter = 0 und sex = 0 (weiblich). In diesem Kontext ist der Achsenabschnitt also rein technisch/hypothetisch zu interpretieren.\nAlter (−0.20266):\nDer Effekt ist nahezu identisch zu Modell 1. Mit jedem Lebensjahr sinkt die Einstellung gegenüber Inklusion im Durchschnitt um ca. 0.20 Punkte. Der Effekt ist signifikant.\nGeschlecht (−0.31568):\nDer negative Koeffizient legt nahe, dass sex = 1 (männlich) mit einer geringfügig negativeren Einstellung verbunden ist – allerdings ist der Effekt nicht signifikant (p = 0.472).\nModellgüte\n\nVarianzaufklärung (R² = 0.3098 / Adjusted R² = 0.3037):\nDas Modell erklärt ca. 30.9% der Varianz – praktisch identisch mit Modell 1. Die zusätzliche Variable (Geschlecht) bringt keinen erkennbaren Vorteil.\nF-Test p-Wert &lt; 2.2e-16:\nDas Gesamtmodell ist signifikant – mindestens ein Prädiktor (hier: Alter) ist bedeutsam."
  },
  {
    "objectID": "literatur.html",
    "href": "literatur.html",
    "title": "Literatur",
    "section": "",
    "text": "In Kürze werden hier einige Bücher und Websites aufgeführt, die bei der Beschäftigung mit Statistik, R und vor allem der Kombination aus beidem hilfreich sind.\nFolgende Titel für Statistik:\nFolgende für das Arbeiten mit R:"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Über",
    "section": "",
    "text": "Diese Seite befindet sich aktuell im Aufbau."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Herzlich willkommen …",
    "section": "",
    "text": "… zur Übung zur Vorlesung Statistik II!\nUnter dem Reiter “Skript” finden Sie die Inhalte der einzelnen Sitzungen; insbesondere also den verwendetet R-Code sowie Kommentare zum Code sowie zu durchgeführten statistischen Analysen.\nDie Seite befindet sich gerade noch im Aufbau. Deswegen werden Sie aktuell noch auf viele Lücken und schwarze Löcher stoßen. Diese sollen allerdings sukzessive befüllt werden.\n Quelle: Artwork by allison_horst"
  },
  {
    "objectID": "Sitzung_1.html",
    "href": "Sitzung_1.html",
    "title": "Übung zu Statistik II - Sitzung 1",
    "section": "",
    "text": "Das kommentierte R-Skript ist auf GRIPS zu finden.\nDie Inhalte werden hier in Kürze nachgeliefert."
  }
]